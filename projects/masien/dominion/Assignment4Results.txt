Nick Masie
2/19/18
CS 362

Assignment 4

1. Random Testing

Other than introducing random testing elements themselves, I tried not to change too much of the development of the original unit/card tests from assignment 3.  Of course there are countless more tests and conditions that I could have introduced in order to increase code coverage just for the sake of increasing code coverage, but I really wanted to focus on the random testing aspects of this assignment in order to see how much that would affect the results.  In regards to the random testing elements, the first obvious method was to have each random cardtest iterate anywhere from 100-1000 times, generating a new and random hand containing the card in question for each iteration.  Theoretically, this alone should massively increase the possibilities of hands and therefore testing conditions (and hopefully code coverage) vs. the 1 iteration of hard coded hands from assignment 3.  The rest of the random testing aspects are card specific, such as generating random cards in a hand for the steward card to trash for choice 3 (trash 2 cards).  A lot of the other aspects of my tests are already handled randomly via the cardEffect() function which already has random aspects built into it such as the random hands/decks to draw from.

2. Code Coverage

Randomtestcard1.c (steward): 87.67% gcov.  This shows a 0.57% decrease in code coverage compared to the 88.24% gcov from the steward card test in assignment 3.  In terms of my gcov for the refactored function playStewardCard(), it successfully hit 94.59%  coverage, which is a slight improvement from last week’s results.

Randomtestcard2.c (smithy): 93.33% gcov.  This shows a 1.44% increase in code coverage compared to the 91.89% gcov from the smithy card test in assignment 3. In terms of my gcov for the refactored function playSmithyCard(),it successfully hit 93.48%  coverage, which is a slight improvement from last week’s results.

Randomtestadventurer.c (adventurer): 93.44% gcov.  This shows a  2.74% increase in code coverage compared to the 90.70% gcov from the adventurer card test in assignment 3.  In terms of my gcov for the refactored function playAdventurerCard(), it successfully hit 93.55%  coverage, which is a slight improvement from last week’s results.
3. Unit vs. Random

Considering the above results and comparing them to the last assignment, they were about what I was expecting.  For the most part, there was an overall increase in code coverage over the card tests themselves, as well as the refactored functions for each respective card test.  I would’ve expected there to be an increase in every single “cardtestfile.c” due to the randomization which increases the likelihood of all possible combinations of conditions, but slight decreases in code coverage for the “cardtestfiles.c” are most likely due to the fact that I was not able to hard code particular failing and passing conditions with random testing in order to make sure that each and every line/possibility was hit like I was able to do in the regular unit tests.  Due to the random testing, some of the tests (however, not all) would either always pass or always fail because I could not manipulate the game in order to produce particular criteria to see if the tests actually work as intended in every possible situation.  However, for most of the card tests where we saw an increase in gcov percentage, I believe that this was due to the random testing elements actually increasing the combinations of game states (mostly via random starting hands, randomly discarding cards in the hand based off particular cards’ actions, etc.).  I believe that my adventurer test provided the best fault detection capabilities because it obviously had the highest code coverage, and the card itself also had a lot of variable combinations of options that were possible when playing the card, so I was able to write a lot more thorough tests in order to test all of these possible combinations that were more likely to be hit by randomized testing, as one can see from the higher code coverage with the adventurer test (this also applies to the smithy test even though the coverage was not as high).  I believe the steward card test was not able to achieve higher code coverage for reasons that I described above, due to the fact that I could not hard code and manipulate particular cases that I knew were unlikely or even unrealistic but still technically possible.  I was a little disappointed by the fact that I could not achieve 100% code coverage with any of my random tests, but I believe this was also due to the fact that I could not hard code unlikely scenarios to occur in order to thoroughly test the respective functions.  I know I could have obviously really dumbed down my code and the tests within simply for the sake of reaching 100% code coverage for at least one of these testse, but I honestly believe that that would be sacrificing the integrity and thoroughness of the overall testing suite, so I decided to accept the roughly 5% deficit and leaving it as is.  I am hoping whoever grades my assignment will consider that and have some mercy on my grade, especially considering I had a lot of trouble getting my makefile to work exactly how I wanted, but that is all described in the README.txt.
